#importing important libraries
import torch, pdb
from torch.utils.data import DataLoader
from torch import nn
from torchvision import transforms
from torchvision.datasets import MNIST
from torchvision.utils import make_grid
from tqdm.auto import tqdm
import matplotlib.pyplot as plt

#visualisation function
def show(tensor ,ch=1, size=(28,28), num = 16):
  data=tensor.detach().cpu().view(-1,ch,*size)
  grid = make_grid(data[:num],nrow=4).permute(1,2,0)
  plt.imshow(grid)
  plt.show()

#setup main paramters and hyper parameters
epochs =500
cur_step = 0
info_step = 300
mean_gen_loss = 0
mean_disc_loss = 0

z_dim = 64
lr=0.001
loss_func = nn.BCEWithLogitsLoss()
#how many images to be processed in GPU
bs = 128
#device to process the data
device = 'cuda' #library to process the images

dataloader = DataLoader(MNIST('.',download=True, transform=transforms.ToTensor()), shuffle=True, batch_size=bs)

#how many steps will be there in each epoch   = total number of images/batch size


#Generator
def genBlock(inp, out):
  return nn.Sequential( #modules will be added to it in the order they are passed in the constructor
      nn.Linear(inp,out), # applies a linear transformation on input size
      nn.BatchNorm1d(out), # because black and white one dimensions images,and applies to the output of previous layer,  it is basically going to normalize the value coming from the previous layer, make the training more stable
      nn.ReLU(inplace=True) # apply non linearity because in multiple linear layers nn will not learn complexity, to train nn for complexity we introduce non linear function in between the linearity, whatever is negative it will make it zero and if it is positive then it will leave it as it is this will help nn to learn more complex functions
  )

class Generator(nn.Module):
  def __init__(self, z_dim=64, i_dim=784, h_dim=128): # z_dim = size of latent vector,i_dim = size of output of the generator = 784 = 28 * 28, h_dim = size of first hidden layer
    super().__init__()
    self.gen = nn.Sequential(  #declare a variable named gen nn.sequential=container or wrapper class that allows you to create a sequential stack of layers in a neural network. which will be composed of number of genBlocks
        genBlock(z_dim, h_dim), #64, 128
        genBlock(h_dim,h_dim*2), #128, 264
        genBlock(h_dim*2,h_dim*4), # 264, 512
        genBlock(h_dim*4,h_dim*8), #512, 1024
        nn.Linear(h_dim*8, i_dim), # 1024, 784 size of MNIST dataset
        nn.Sigmoid()  # we want pixels of the data between 0 and 1 so we will apply sigmoid function
    )
  def forward(self,noise):
    return self.gen(noise)


def gen_noise(number, z_dim):
  return torch.randn(number, z_dim).to(device)  #we will store this noise to our GPU

## Discriminator

def discBlock(inp,out):
  return nn.Sequential(
      nn.Linear(inp,out),
      nn.LeakyReLU(0.2), #instead of giving zero value to negative number it will give give a small negitive value on slope which is equl to the parameter which is equal to 0.2, this is used in discriminator espacially which will make the training better
  )


class Discriminator(nn.Module):
  def __init__(self, i_dim=784, h_dim=256):
    super().__init__()
    self.disc=nn.Sequential(
        discBlock(i_dim, h_dim*4),    # 784, 1024 we will start with big output because in the lst we will have to make the output 1 as it will tell if the image i fake or real
        discBlock(h_dim*4, h_dim*2),
        discBlock(h_dim*2, h_dim),
        nn.Linear(h_dim,1)                #256,1
    )
  def forward(self,image):
    return self.disc(image)



gen = Generator(z_dim).to(device)
gen_opt = torch.optim.Adam(gen.parameters(),lr=lr)

disc= Discriminator().to(device)
disc_opt=torch.optim.Adam(disc.parameters(),lr=lr)


x,y=next(iter(dataloader)) 
print(x.shape, y.shape)
print(y[:10])

noise = gen_noise(bs,z_dim)# we are making a fake image with literally nothing
fake=gen(noise)
show(fake)

#calculating the loss

#generator loss
def calc_gen_loss(loss_func, gen, disc, number, z_dim):
  noise=gen_noise(number,z_dim) #we obtain a noise vector which is a size of the batch amd we are givng the input in it
  fake = gen(noise)
  pred = disc(fake)  #generator will try to fool the discriminator that the images it make are real
  targets=torch.ones_like(pred)
  gen_loss=loss_func(pred,targets)
  return gen_loss

def calc_disc_loss(loss_func, gen, disc,number,real,z_dim):
  noise = gen_noise(number,z_dim)
  fake=gen(noise)
  disc_fake=disc(fake.detach())
  disc_fake_target=torch.zeros_like(disc_fake)
  disc_fake_loss = loss_func(disc_fake, disc_fake_target)

  disc_real = disc(real)
  disc_real_targets= torch.ones_like(disc_real)
  disc_real_loss=loss_func(disc_real,disc_real_targets)

  disc_loss = (disc_fake_loss+disc_real_loss)/2

  return disc_loss

### 60000 / 128 = 468.75 = 469 steps in each epoch

for epoch in range(epochs):
  for real, _ in tqdm(dataloader):
    ### discriminator
    disc_opt.zero_grad()

    cur_bs=len(real) # real: 128 x 1 x 28 x 28
    real = real.view(cur_bs, -1) # 128 x 784
    real = real.to(device)

    disc_loss = calc_disc_loss(loss_func,gen,disc,cur_bs,real,z_dim)
    disc_loss.backward(retain_graph=True)
    disc_opt.step()

    ### generator
    gen_opt.zero_grad()
    gen_loss = calc_gen_loss(loss_func,gen,disc,cur_bs,z_dim)
    gen_loss.backward(retain_graph=True)
    gen_opt.step()

    ### visualization & stats
    mean_disc_loss+=disc_loss.item()/info_step
    mean_gen_loss+=gen_loss.item()/info_step

    if cur_step % info_step == 0 and cur_step>0:
      fake_noise = gen_noise(cur_bs, z_dim)
      fake = gen(fake_noise)
      show(fake)
      show(real)
      print(f"{epoch}: step {cur_step} / Gen loss: {mean_gen_loss} / disc_loss: {mean_disc_loss}")
      mean_gen_loss, mean_disc_loss=0,0
    cur_step+=1
